{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "55ddb7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from operator import add\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import StopWordsRemover, VectorAssembler\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "sc = SparkSession.builder.getOrCreate()\n",
    "spark = SparkSession.builder.appName('FinalProject').getOrCreate()\n",
    "\n",
    "# Get sparkcontext from \n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0188cb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA Business count: 5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Reviews count: 16472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+------------+-------------------+------+-----+----+----+-------------+\n",
      "|             user_id|name|review_count|      yelping_since|useful|funny|cool|fans|average_stars|\n",
      "+--------------------+----+------------+-------------------+------+-----+----+----+-------------+\n",
      "|hCAuMs7R7FFh4gbkM...|Chon|         370|2009-12-25 23:15:20|   319|  127| 154|  14|         3.77|\n",
      "|OyLO6fl4st6r_YX-L...|Mish|          59|2009-06-23 22:52:52|    47|   18|  35|   2|          3.8|\n",
      "+--------------------+----+------------+-------------------+------+-----+----+----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users count: 16472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ERASING ALL JSON FROM LOCAL\n",
    "\n",
    "df_business = spark.read.json('/Volumes/Nischay HDD/yelp_academic_dataset_business.json')\n",
    "df_reviews  = spark.read.json('/Volumes/Nischay HDD/yelp_academic_dataset_review.json')\n",
    "df_users  = spark.read.json('/Volumes/Nischay HDD/yelp_academic_dataset_user.json')\n",
    "\n",
    "\n",
    "# FILTERING DATASET TO VANCOUVER\n",
    "\n",
    "df_business_VA = df_business.select('business_id', 'name',  'address', 'city', \\\n",
    "                                      'state', 'postal_code', 'latitude', 'longitude', 'stars', 'review_count', 'categories') \\\n",
    "                                .filter( (df_business.city == 'Vancouver') & (df_business.categories.contains('Restaurants') ) )\n",
    "\n",
    "business_count = df_business_VA.count()\n",
    "print(f'MA Business count: {business_count}')\n",
    "\n",
    "# Sampling data to run on local\n",
    "sampled_business_MA = df_business_VA.sample(0.01)\n",
    "\n",
    "\n",
    "# FETCHING USER REVIEWS FOR FILTERED BUSINESES\n",
    "\n",
    "df_reviews_MA = df_reviews.join(sampled_business_MA, on = 'business_id', how = 'inner') \\\n",
    "                          .select(df_reviews.business_id, df_reviews.user_id, df_reviews.review_id, df_reviews.stars)\n",
    "df_reviews_count = df_reviews_MA.count()\n",
    "print(f'Business Reviews count: {df_reviews_count}')\n",
    "\n",
    "\n",
    "\n",
    "# FETCHING USERS\n",
    "df_users_MA = df_users.join(df_reviews_MA, on = 'user_id', how = 'inner') \\\n",
    "                          .select(df_users.user_id, df_users.name, df_users.review_count, df_users.yelping_since, \\\n",
    "                                  df_users.useful, df_users.funny , df_users.cool , df_users.fans , df_users.average_stars)\n",
    "df_users_MA.show(2)\n",
    "\n",
    "df_users_MA_count = df_users_MA.count()\n",
    "print(f'Users count: {df_users_MA_count}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# WRITRING THE DFs into paraquet\n",
    "\n",
    "sampled_business_MA.coalesce(1).write.parquet('New_Small_Datasets/small_business_datset')\n",
    "df_reviews_MA.coalesce(1).write.parquet('New_Small_Datasets/small_reviews_dataset')\n",
    "df_users_MA.coalesce(1).write.parquet('New_Small_Datasets/small_users_dataset')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "639bab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 96:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business COunt: 256\n",
      "Reviews COunt: 16472\n",
      "Users COunt: 16472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read data generated from above process\n",
    "business_df = spark.read.parquet('New_Small_Datasets/small_business_datset')\n",
    "business_count = business_df.count()\n",
    "\n",
    "reviews_df = spark.read.parquet('New_Small_Datasets/small_reviews_dataset')\n",
    "reviews_count = reviews_df.count()\n",
    "\n",
    "users_df = spark.read.parquet('New_Small_Datasets/small_users_dataset')\n",
    "users_count = users_df.count()\n",
    "\n",
    "print(f'Business COunt: {business_count}')\n",
    "print(f'Reviews COunt: {reviews_count}')\n",
    "print(f'Users COunt: {users_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14467cb",
   "metadata": {},
   "source": [
    "### Creating ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "70accf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "busineses_sql_df = spark.read\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost/food_hunter_development\")\\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\")\\\n",
    "    .option(\"dbtable\", \"restaurants\").option(\"user\", \"root\")\\\n",
    "    .option(\"password\", \"Nanu1996\").load()\n",
    "\n",
    "users_sql_df = spark.read\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost/food_hunter_development\")\\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\")\\\n",
    "    .option(\"dbtable\", \"users\").option(\"user\", \"root\")\\\n",
    "    .option(\"password\", \"Nanu1996\").load()\n",
    "\n",
    "reviews_sql_df = spark.read\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost/food_hunter_development\")\\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\")\\\n",
    "    .option(\"dbtable\", \"reviews\").option(\"user\", \"root\")\\\n",
    "    .option(\"password\", \"Nanu1996\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7d11d795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------+-----+--------------------+--------------------+\n",
      "|   id|restaurant_id|user_id|stars|          created_at|          updated_at|\n",
      "+-----+-------------+-------+-----+--------------------+--------------------+\n",
      "|16473|         2731|  11079|  1.0|2022-04-03 07:37:...|2022-04-03 07:37:...|\n",
      "|16474|         2747|   8720|  1.0|2022-04-03 07:37:...|2022-04-03 07:37:...|\n",
      "|16475|         2753|  11903|  5.0|2022-04-03 07:37:...|2022-04-03 07:37:...|\n",
      "|16476|         2740|   4151|  1.0|2022-04-03 07:37:...|2022-04-03 07:37:...|\n",
      "|16477|         2732|   3695|  3.0|2022-04-03 07:37:...|2022-04-03 07:37:...|\n",
      "+-----+-------------+-------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_sql_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d0eb8c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  16\n",
      "CrossValidator_061c47aea2bb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36872:===========================================>          (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.recommendation.ALSModel'>\n",
      "**Best Model**\n",
      "  Rank: 150\n",
      "  MaxIter: 10\n",
      "  RegParam: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 36872:================================================>     (9 + 1) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import to_json,col\n",
    "\n",
    "\n",
    "reviews_sql_df = spark.read\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost/food_hunter_development\")\\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\")\\\n",
    "    .option(\"dbtable\", \"reviews\").option(\"user\", \"root\")\\\n",
    "    .option(\"password\", \"Nanu1996\").load()\n",
    "\n",
    "\n",
    "(train, test) = reviews_sql_df.randomSplit([0.8, 0.2], seed = 1234)\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"restaurant_id\", ratingCol=\"stars\", nonnegative = True, implicitPrefs = False, coldStartStrategy=\"drop\")\n",
    "\n",
    "# Confirm that a model called \"als\" was created\n",
    "type(als)\n",
    "\n",
    "\n",
    "\n",
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50, 100, 150]) \\\n",
    "            .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
    "            .build()\n",
    "            #             .addGrid(als.maxIter, [5, 50, 100, 200]) \\\n",
    "\n",
    "           \n",
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"stars\", predictionCol=\"prediction\") \n",
    "print (\"Num models to be tested: \", len(param_grid))\n",
    "\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Confirm cv was built\n",
    "print(cv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Fit cross validator to the 'train' dataset\n",
    "model = cv.fit(train)\n",
    "\n",
    "#Extract best model from the cv model above\n",
    "best_model = model.bestModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print best_model\n",
    "print(type(best_model))\n",
    "\n",
    "# Complete the code below to extract the ALS model parameters\n",
    "print(\"**Best Model**\")\n",
    "\n",
    "# # Print \"Rank\"\n",
    "print(\"  Rank:\", best_model._java_obj.parent().getRank())\n",
    "\n",
    "# Print \"MaxIter\"\n",
    "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
    "\n",
    "# Print \"RegParam\"\n",
    "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "679d8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4273658210501932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# View the predictions\n",
    "test_predictions = best_model.transform(test)\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)\n",
    "\n",
    "\n",
    "nrecommendations = best_model.recommendForAllUsers(20)\n",
    "nrecommendations_json = nrecommendations.select('user_id', to_json(col('recommendations'))).withColumnRenamed(\"to_json(recommendations)\",\"recommendations\")\n",
    "\n",
    "nrecommendations_json.write.option(\"truncate\", \"true\").format('jdbc').options(\n",
    "      url='jdbc:mysql://localhost/food_hunter_development',\n",
    "      driver='com.mysql.jdbc.Driver',\n",
    "      dbtable='user_recommendations',\n",
    "      user='root',\n",
    "      password='Nanu1996').mode(\"overwrite\").save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a42b7b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------+-----+--------------------+--------------------+----------+\n",
      "|   id|restaurant_id|user_id|stars|          created_at|          updated_at|prediction|\n",
      "+-----+-------------+-------+-----+--------------------+--------------------+----------+\n",
      "|16530|         2731|   9376|  3.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 3.3832917|\n",
      "|16884|         2760|   5803|  5.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 3.1077015|\n",
      "|17731|         2743|  11458|  5.0|2022-04-03 07:37:...|2022-04-03 07:37:...|   3.78815|\n",
      "|19991|         2795|  13289|  4.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 3.3819737|\n",
      "|25956|         2903|  11858|  5.0|2022-04-03 07:37:...|2022-04-03 07:37:...|  3.355189|\n",
      "|26237|         2893|   9376|  4.0|2022-04-03 07:37:...|2022-04-03 07:37:...|  3.186566|\n",
      "|27619|         2903|   6654|  2.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 2.7607985|\n",
      "|28586|         2914|   5803|  4.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 3.9960735|\n",
      "|18064|         2783|   8928|  2.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 3.3717868|\n",
      "|18642|         2790|   8928|  5.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 2.9425006|\n",
      "|20378|         2792|  11500|  3.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 3.8058212|\n",
      "|20626|         2810|  10121|  4.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 2.3712008|\n",
      "|21209|         2839|  15254|  3.0|2022-04-03 07:37:...|2022-04-03 07:37:...|  4.230395|\n",
      "|21773|         2814|   8928|  2.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 3.2081692|\n",
      "|22798|         2815|  11500|  5.0|2022-04-03 07:37:...|2022-04-03 07:37:...|  4.534002|\n",
      "|24068|         2845|  15254|  4.0|2022-04-03 07:37:...|2022-04-03 07:37:...|  2.731537|\n",
      "|25596|         2897|  19200|  4.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 4.9987416|\n",
      "|31225|         2946|  10121|  4.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 3.5193346|\n",
      "|16966|         2760|   5071|  4.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 3.3762214|\n",
      "|17357|         2758|   8257|  4.0|2022-04-03 07:37:...|2022-04-03 07:37:...| 3.5015342|\n",
      "+-----+-------------+-------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b633aaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37372:=================================================>  (95 + 5) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------+\n",
      "|user_id|                                             recommendations|\n",
      "+-------+------------------------------------------------------------+\n",
      "|   3566|[{\"restaurant_id\":2957,\"rating\":4.999135},{\"restaurant_id...|\n",
      "|   3582|[{\"restaurant_id\":2861,\"rating\":4.9140463},{\"restaurant_i...|\n",
      "|   3587|[{\"restaurant_id\":2791,\"rating\":4.999191},{\"restaurant_id...|\n",
      "|   3691|[{\"restaurant_id\":2855,\"rating\":1.3261416},{\"restaurant_i...|\n",
      "|   3706|[{\"restaurant_id\":2945,\"rating\":1.0624769},{\"restaurant_i...|\n",
      "|   3725|[{\"restaurant_id\":2962,\"rating\":2.1796079},{\"restaurant_i...|\n",
      "|   3761|[{\"restaurant_id\":2815,\"rating\":2.2087924},{\"restaurant_i...|\n",
      "|   3790|[{\"restaurant_id\":2945,\"rating\":2.8243268},{\"restaurant_i...|\n",
      "|   3794|[{\"restaurant_id\":2909,\"rating\":3.9905057},{\"restaurant_i...|\n",
      "|   3834|[{\"restaurant_id\":2791,\"rating\":5.035022},{\"restaurant_id...|\n",
      "|   3997|[{\"restaurant_id\":2827,\"rating\":3.9992065},{\"restaurant_i...|\n",
      "|   4042|[{\"restaurant_id\":2827,\"rating\":4.999009},{\"restaurant_id...|\n",
      "|   4097|[{\"restaurant_id\":2861,\"rating\":5.1896486},{\"restaurant_i...|\n",
      "|   4119|[{\"restaurant_id\":2973,\"rating\":4.2417164},{\"restaurant_i...|\n",
      "|   4126|[{\"restaurant_id\":2945,\"rating\":2.1881526},{\"restaurant_i...|\n",
      "|   4132|[{\"restaurant_id\":2878,\"rating\":4.4975357},{\"restaurant_i...|\n",
      "|   4153|[{\"restaurant_id\":2945,\"rating\":5.38532},{\"restaurant_id\"...|\n",
      "|   4167|[{\"restaurant_id\":2745,\"rating\":3.1452296},{\"restaurant_i...|\n",
      "|   4181|[{\"restaurant_id\":2945,\"rating\":5.112517},{\"restaurant_id...|\n",
      "|   4186|[{\"restaurant_id\":2821,\"rating\":4.999178},{\"restaurant_id...|\n",
      "+-------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nrecommendations_json.show(20, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2102624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
